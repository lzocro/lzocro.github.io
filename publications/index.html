<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Lorenzo Croissant</title> <meta name="author" content="Lorenzo Croissant"/> <meta name="description" content="Personal Webpage of Lorenzo Croissant. "/> <meta name="keywords" content="lorenzo-croissant, lorenzo, croissant, control-theory, RL, reinforcement-learning, auction, auctions, auction-theory, jekyll, jekyll-theme, academic-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü•ê</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://lzocro.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Lorenzo Croissant</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Other</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/blog/">Blog</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/events/">Events</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/github/">GitHub</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2026</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="Croissant_BOT_25" class="col-sm-8"> <div class="title">Bandit Optimal Transport</div> <div class="author"> <em>Lorenzo Croissant</em> </div> <div class="periodical"> Feb 2026 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04938170" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://hal.science/hal-04938170v2/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/BOT/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>Linear bandits have long been a central topic in online learning, with applications ranging from recommendation systems to adaptive clinical trials. Their general learnability has been established when the objective is to minimise the inner product between a cost parameter and the decision variable. While this is highly general, this reliance on an inner product structure belies the name of <i>linear</i> bandits, and fails to account for problems such as Optimal Transport. Using the Kantorovich formulation of Optimal Transport as an example, we show that an inner product structure is <i>not</i> necessary to achieve efficient learning in linear bandits. We propose a refinement of the classical OFUL algorithm that operates by embedding the action set into a Hilbertian subspace, where confidence sets can be built via least-squares estimation. Actions are then constrained to this subspace by penalising optimism. The analysis is completed by leveraging convergence results from penalised (entropic) transport to the Kantorovich problem. Up to this approximation term, the resulting algorithm achieves the same trajectorial regret upper bounds as the OFUL algorithm, which we turn into worst-case regret using functional regression techniques. Its regret interpolates between \(\tilde{O}(\sqrt{T})\,\)and \({O}(T)\), depending on the regularity of the cost function, and recovers the parametric rate \(\tilde{O}(\sqrt{dT})\,\)in finite-dimensional settings. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">Croissant_BOT_25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bandit {Optimal} {Transport}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Bandit Algorithms, Optimal transport}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="verronneau25" class="col-sm-8"> <div class="title">FeatHawkes: Scalable Feature-Based Attribution For Temporal Event Data</div> <div class="author"> <a href="https://crest.science/user/R%C3%A9mi-VERRONNEAU/" target="_blank" rel="noopener noreferrer">Remi Verronneau</a>,¬†<em>Lorenzo Croissant</em>,¬†Bartholome Vieille, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Vianney Perchet' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> Feb 2026 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-05284437" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://hal.science/hal-05284437v2/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>Attribution, the problem of assigning proportional responsibility for an outcome to each event in a temporal sequence, is central to diverse applications ranging from marketing and seismology to sports analytics. While incorporating exogenous features substantially enhances the expressiveness of attribution models, existing approaches lack the scalability required to integrate modern machine learning. We introduce FeatHawkes, a feature-augmented Hawkes process framework for event-level attribution in continuous time. Our core contribution is a novel first-order optimization routine for Hawkes processes that leverages stochastic gradient methods, scaling favorably with both dataset size and feature dimensionality. This gradient-based formulation enables compatibility with automatic differentiation and end-to-end machine learning pipelines. We release FeatHawkes as an open-source Python library and demonstrate its effectiveness through synthetic experiments and a case study on professional football data, where the framework supports scenario-based analyses, such as evaluating the modelled effect of player substitutions in a lineup. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@unpublished</span><span class="p">{</span><span class="nl">verronneau25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FeatHawkes: Scalable Feature-Based Attribution For Temporal Event Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verronneau, Remi and Croissant, Lorenzo and Vieille, Bartholome and Perchet, Vianney}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-05284437}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{working paper or preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2026}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-05284437}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v2}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_4322.jpg"></div> <div id="ABC25" class="col-sm-8"> <div class="title">Diffusive limit approximation of pure jump optimal ergodic control problems</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a>,¬†and¬†<em>Lorenzo Croissant</em> </div> <div class="periodical"> <em>Stochastic Processes and their Applications</em> Mar 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0304414924002448" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/diffusion_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>Motivated by the design of fast reinforcement learning algorithms, see (Croissant <i>et al</i>., 2024), we study the diffusive limit of a class of pure jump ergodic stochastic control problems. We show that, whenever the intensity of jumps \(\varepsilon\,\)is large enough, the approximation error is governed by the H√∂lder regularity of the Hessian matrix of the solution to the limit ergodic partial differential equation and is, indeed, of order \(\varepsilon^\fracŒ≥2\,\)for all \(Œ≥‚àà(0,1)\). This extends to this context the results of Abeille <i>et al</i>. (2023) obtained for finite horizon problems. Using the limit as an approximation, instead of directly solving the pre-limit problem, allows for a very significant reduction in the numerical resolution cost of the control problem. Additionally, we explain how error correction terms of this approximation can be constructed under appropriate smoothness assumptions. Finally, we quantify the error induced by the use of the Markov control policy constructed from the numerical finite difference scheme associated to the limit diffusive problem, which seems to be new in the literature and of independent interest.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ABC25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusive limit approximation of pure jump optimal ergodic control problems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{181}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{03044149}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.spa.2024.104536}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-12-05}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Stochastic Processes and their Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abeille, Marc and Bouchard, Bruno and Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104536}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5318.jpg"></div> <div id="Benomar25" class="col-sm-8"> <div class="title">Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=ZhWGR7QAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Ziyad Benomar</a>,¬†<em>Lorenzo Croissant</em>,¬†<a href="https://vianney.ai" target="_blank" rel="noopener noreferrer">Vianney Perchet</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Spyros Angelopoulos' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 42nd International Conference on Machine Learning</em> 13‚Äì19 jul 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v267/benomar25a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://raw.githubusercontent.com/mlresearch/v267/main/assets/benomar25a/benomar25a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/Alps/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximise its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Benomar25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benomar, Ziyad and Croissant, Lorenzo and Perchet, Vianney and Angelopoulos, Spyros}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 42nd International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3776--3805}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Singh, Aarti and Fazel, Maryam and Hsu, Daniel and Lacoste-Julien, Simon and Berkenkamp, Felix and Maharaj, Tegan and Wagstaff, Kiri and Zhu, Jerry}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{267}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{13--19 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="CAB23" class="col-sm-8"> <div class="title">Near-continuous time Reinforcement Learning for continuous state-action spaces</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a> </div> <div class="periodical"> <em>In Proceedings of the 35th International Conference on Algorithmic Learning Theory</em> 25‚Äì28 feb 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v237/croissant24a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://proceedings.mlr.press/v237/croissant24a/croissant24a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/RL_diff_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p> We consider the reinforcement learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for systems in which interactions occur at a high frequency, if not in continuous time, or those whose state spaces are large if not inherently continuous. Perhaps the only exception is the linear quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency \(\varepsilon^{-1}\,\)which captures arbitrary time scales from discrete (\(\varepsilon=1\)) to continuous time (\(\varepsilon\downarrow0\)). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on \(R^d\). We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning by extending the eluder dimension framework and propose an approximate planning method based on a diffusive limit (\(\varepsilon\downarrow0\)) approximation of the jump process. Overall, our algorithm enjoys a regret of order \(\tilde{O}(\sqrt{T})\,\)or \(\tilde{O}(\varepsilon^{1/2} T+\sqrt{T})\,\)with the approximate planning. As the frequency of interactions blows up, the approximation error \(\varepsilon^{1/2} ‚ÄØT\,\)vanishes, showing that \(\tilde{O}(\sqrt{T})\,\)is attainable in near-continuous time. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAB23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Bouchard, Bruno}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Near-continuous time {Reinforcement} {Learning} for continuous state-action spaces}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{444-498}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the {35th} International Conference on Algorithmic Learning Theory}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{25--28 Feb}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="thesis" class="col-sm-8"> <div class="title">Diffusion limit control and reinforcement learning, with applications to online auctions</div> <div class="author"> <em>Lorenzo Croissant</em> </div> <div class="periodical"> 25‚Äì28 feb 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://theses.hal.science/tel-04356751/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://theses.hal.science/tel-04356751v1/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p> We consider the diffusive limit of a generic pure-jump Markov control problem as the intensity of the driving Poisson process tends to infinity. We quantify the convergence speed in terms of the H√∂lder exponent of the Hessian of the limit problem. This approximation provides an efficient alternative method for the numerical resolution of these problems when the intensity of jumps is large. Considering the control of unknown systems, we extend this approach to the context of online Reinforcement Learning. Under the OFU paradigm, we leverage the eluder dimension framework for learning and the diffusive limit for approximate resolution of the planning sub-problem. Our algorithm extends existing theory from discrete processes to continuous states and actions. Our study of diffusion limit systems is motivated and illustrated by the bidding problem in a high-frequency online auction against a revenue-maximising seller. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">thesis</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Universit√© Paris-Dauphine, Universit√© PSL}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusion limit control and reinforcement learning, with applications to online auctions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://theses.hal.science/tel-04356751/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="CAB23EWRL" class="col-sm-8"> <div class="title">Reinforcement Learning in near-continuous time for continuous state-action spaces</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a> </div> <div class="periodical"> <em>In Sixteenth European Workshop on Reinforcement Learning</em> Sep 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=bqiRIs3fJNk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://openreview.net/pdf?id=bqiRIs3fJNk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/RL_diff_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p> We consider the reinforcement learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for systems in which interactions occur at a high frequency, if not in continuous time, or those whose state spaces are large if not inherently continuous. Perhaps the only exception is the linear quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency \(\varepsilon^{-1}\,\)which captures arbitrary time scales from discrete (\(\varepsilon=1\,\)) to continuous time (\(\varepsilon\downarrow0\)). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on \(R^d\). We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning by extending the eluder dimension framework and propose an approximate planning method based on a diffusive limit (\(\varepsilon\downarrow0\)) approximation of the jump process. Overall, our algorithm enjoys a regret of order \(\tilde{O}(\sqrt{T})\,\)or \(\tilde{O}(\varepsilon^{1/2} T+\sqrt{T})\,\)with the approximate planning. As the frequency of interactions blows up, the approximation error \(\varepsilon^{1/2} ‚ÄØT\,\)vanishes, showing that \(\tilde{O}(\sqrt{T})\,\)is attainable in near-continuous time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAB23EWRL</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reinforcement Learning in near-continuous time for continuous state-action spaces}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Bouchard, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Sixteenth European Workshop on Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=bqiRIs3fJNk}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="ABC21" class="col-sm-8"> <div class="title">Diffusive limit approximation of pure-jump optimal stochastic control problems</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a>,¬†and¬†<em>Lorenzo Croissant</em> </div> <div class="periodical"> <em>Journal of Optimization Theory and Applications</em> 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2106.12848" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10957-022-02135-7" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2106.12848" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/diffusion_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>We consider the diffusive limit of a typical pure-jump Markovian control problem as the intensity of the driving Poisson process tends to infinity. We show that the convergence speed is provided by the H√∂lder constant of the Hessian of the limit problem, and explain how correction terms can be constructed. This provides an alternative efficient method for the numerical approximation of the optimal control of a pure-jump problem in situations with very high intensity of jump. We illustrate this approach in the context of a display advertising auction problem.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ABC21</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusive limit approximation of pure-jump optimal stochastic control problems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abeille, Marc and Bouchard, Bruno and Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Optimization Theory and Applications}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--30}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{ 10.1007/s10957-022-02135-7}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.1007/s10957-022-02135-7}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5318.jpg"></div> <div id="CAC20" class="col-sm-8"> <div class="title">Real-Time Optimisation for Online Learning in Auctions</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://scholar.google.fr/citations?user=lFsKnyUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Clement Calauzenes</a> </div> <div class="periodical"> <em>In Proceedings of the 37th International Conference on Machine Learning</em> 13‚Äì18 jul 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2010.10070" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v119/croissant20a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2010.10070" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/projects/Online_learning_auctions/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>In display advertising, a small group of sellers and bidders face each other in up to \(10^{12}\)auctions a day. In this context, revenue maximisation via monopoly price learning is a high-value problem for sellers. By nature, these auctions are online and produce a very high frequency stream of data. This results in a computational strain that requires algorithms be real-time. Unfortunately, existing methods inherited from the batch setting suffer \(O(\sqrt{t})\)time/memory complexity at each update, prohibiting their use. In this paper, we provide the first algorithm for online learning of monopoly prices in online auctions whose update is constant in time and memory.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAC20</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Optimisation for Online Learning in Auctions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Calauzenes, Clement}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 37th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2217--2226}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{III, Hal Daum√© and Singh, Aarti}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{119}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{13--18 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2026 Lorenzo Croissant. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos by myself. Last updated: February 17, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams",maxBuffer:10240,maxMacros:10240}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>