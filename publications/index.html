<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Publications | Lorenzo Croissant</title> <meta name="author" content="Lorenzo Croissant"/> <meta name="description" content="Personal Webpage of Lorenzo Croissant, PhD in mathematics from Universite Paris Dauphine. Currently working at CREST, ENSAE Paris, and Inria (FairPlay team). "/> <meta name="keywords" content="lorenzo-croissant, lorenzo, croissant, control-theory, RL, reinforcement-learning, auction, auctions, auction-theory, jekyll, jekyll-theme, academic-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü•ê</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://lzocro.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Lorenzo Croissant</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Other</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/projects/">Projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/events/">Events</a> <div class="dropdown-divider"></div> <a class="dropdown-item" href="/github/">GitHub</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <div class="publications"> <h2 class="year">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_4322.jpg"></div> <div id="ABC25" class="col-sm-8"> <div class="title">Diffusive limit approximation of pure jump optimal ergodic control problems</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a>,¬†and¬†<em>Lorenzo Croissant</em> </div> <div class="periodical"> <em>Stochastic Processes and their Applications</em> Mar 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/S0304414924002448" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2022/Diffusion-limit-ergodic-optimal-control/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/diffusion_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ABC25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusive limit approximation of pure jump optimal ergodic control problems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{181}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{03044149}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.spa.2024.104536}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2024-12-05}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Stochastic Processes and their Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abeille, Marc and Bouchard, Bruno and Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{104536}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5318.jpg"></div> <div id="Benomar25" class="col-sm-8"> <div class="title">Pareto-Optimality, Smoothness, and Stochasticity in Learning-Augmented One-Max-Search</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=ZhWGR7QAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Ziyad Benomar</a>,¬†<em>Lorenzo Croissant</em>,¬†<a href="https://vianney.ai" target="_blank" rel="noopener noreferrer">Vianney Perchet</a>, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Spyros Angelopoulos' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> Feb 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2502.05720" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://arxiv.org/abs/2502.05720" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2502.05720" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/Alps/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>One-max search is a classic problem in online decision-making, in which a trader acts on a sequence of revealed prices and accepts one of them irrevocably to maximise its profit. The problem has been studied both in probabilistic and in worst-case settings, notably through competitive analysis, and more recently in learning-augmented settings in which the trader has access to a prediction on the sequence. However, existing approaches either lack smoothness, or do not achieve optimal worst-case guarantees: they do not attain the best possible trade-off between the consistency and the robustness of the algorithm. We close this gap by presenting the first algorithm that simultaneously achieves both of these important objectives. Furthermore, we show how to leverage the obtained smoothness to provide an analysis of one-max search in stochastic learning-augmented settings which capture randomness in both the observed prices and the prediction.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">Benomar25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pareto-{Optimality}, {Smoothness}, and {Stochasticity} in {Learning}-{Augmented} {One}-{Max}-{Search}}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{All rights reserved}</span><span class="p">,</span>
  <span class="na">urldate</span> <span class="p">=</span> <span class="s">{2025-02-11}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Benomar, Ziyad and Croissant, Lorenzo and Perchet, Vianney and Angelopoulos, Spyros}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Computer Science - Artificial Intelligence, Computer Science - Data Structures and Algorithms}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="Croissant_BOT_25" class="col-sm-8"> <div class="title">Bandit Optimal Transport</div> <div class="author"> <em>Lorenzo Croissant</em> </div> <div class="periodical"> Feb 2025 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/https://hal.science/hal-04938170v1/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-04938170" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://hal.science/hal-04938170v1/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/BOT/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>Despite the impressive progress in statistical Optimal Transport (OT) in recent years, there has been little interest in the study of the }emph{sequential learning} of OT. Surprisingly so, as this problem is both practically motivated and a challenging extension of existing settings such as linear bandits. This article considers (for the first time) the stochastic bandit problem of learning to solve generic Kantorovich and entropic OT problems from repeated interactions when the marginals are known but the cost is unknown. We provide \tildeO(\sqrtT) regret algorithms for both problems by extending linear bandits on Hilbert spaces. These results provide a reduction to infinite-dimensional linear bandits. To deal with the dimension, we provide a method to exploit the intrinsic regularity of the cost to learn, yielding corresponding regret bounds which interpolate between \tildeO(\sqrtT) and \tildeO(T).</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">Croissant_BOT_25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Bandit {Optimal} {Transport}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Bandit Algorithms, Optimal transport}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="verronneau25" class="col-sm-8"> <div class="title">FeatHawkes: Scalable Feature-Based Attribution For Temporal Event Data</div> <div class="author"> <a href="https://crest.science/user/R%C3%A9mi-VERRONNEAU/" target="_blank" rel="noopener noreferrer">Remi Verronneau</a>,¬†<em>Lorenzo Croissant</em>,¬†Bartholome Vieille, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Vianney Perchet' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> Sep 2025 </div> <div class="links"> <a href="http://arxiv.org/abs/https://hal.science/hal-05284437" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/hal-05284437" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://hal.science/hal-05284437v1/file/FeatHawkes.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@unpublished</span><span class="p">{</span><span class="nl">verronneau25</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FeatHawkes: Scalable Feature-Based Attribution For Temporal Event Data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Verronneau, Remi and Croissant, Lorenzo and Vieille, Bartholome and Perchet, Vianney}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://hal.science/hal-05284437}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{working paper or preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">sep</span><span class="p">,</span>
  <span class="na">hal_id</span> <span class="p">=</span> <span class="s">{hal-05284437}</span><span class="p">,</span>
  <span class="na">hal_version</span> <span class="p">=</span> <span class="s">{v1}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="CAB23" class="col-sm-8"> <div class="title">Near-continuous time Reinforcement Learning for continuous state-action spaces</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a> </div> <div class="periodical"> <em>In Proceedings of the 35th International Conference on Algorithmic Learning Theory</em> 25‚Äì28 feb 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.mlr.press/v237/croissant24a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://proceedings.mlr.press/v237/croissant24a/croissant24a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2023/Online-non-episodic-RL/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/RL_diff_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p> We consider the reinforcement learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for systems in which interactions occur at a high frequency, if not in continuous time, or those whose state spaces are large if not inherently continuous. Perhaps the only exception is the linear quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency \varepsilon^-1 which captures arbitrary time scales from discrete (\varepsilon=1) to continuous time (\varepsilon\downarrow0). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on \mathbbR^d. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning by extending the eluder dimension framework and propose an approximate planning method based on a diffusive limit (\varepsilon\downarrow0) approximation of the jump process. Overall, our algorithm enjoys a regret of order \tilde\mathcalO(\sqrtT) or \tilde\mathcalO(\varepsilon^1/2 T+\sqrtT) with the approximate planning. As the frequency of interactions blows up, the approximation error \varepsilon^1/2 T vanishes, showing that \tilde\mathcalO(\sqrtT) is attainable in near-continuous time. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAB23</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Bouchard, Bruno}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Near-continuous time {Reinforcement} {Learning} for continuous state-action spaces}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{444-498}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the {35th} International Conference on Algorithmic Learning Theory}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{25--28 Feb}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="year">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="thesis" class="col-sm-8"> <div class="title">Diffusion limit control and reinforcement learning, with applications to online auctions</div> <div class="author"> <em>Lorenzo Croissant</em> </div> <div class="periodical"> 25‚Äì28 feb 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://theses.hal.science/tel-04356751/" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://theses.hal.science/tel-04356751v1/document" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p> We consider the diffusive limit of a generic pure-jump Markov control problem as the intensity of the driving Poisson process tends to infinity. We quantify the convergence speed in terms of the H√∂lder exponent of the Hessian of the limit problem. This approximation provides an efficient alternative method for the numerical resolution of these problems when the intensity of jumps is large. Considering the control of unknown systems, we extend this approach to the context of online Reinforcement Learning. Under the \acrlongOFU paradigm, we leverage the eluder dimension framework for learning and the diffusive limit for approximate resolution of the planning sub-problem. Our algorithm extends existing theory from discrete processes to continuous states and actions. Our study of diffusion limit systems is motivated and illustrated by the bidding problem in a high-frequency online auction against a revenue-maximising seller. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">thesis</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{Universit√© Paris-Dauphine, Universit√© PSL}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusion limit control and reinforcement learning, with applications to online auctions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://theses.hal.science/tel-04356751/}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="CAB23EWRL" class="col-sm-8"> <div class="title">Reinforcement Learning in near-continuous time for continuous state-action spaces</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a> </div> <div class="periodical"> <em>In Sixteenth European Workshop on Reinforcement Learning</em> 25‚Äì28 feb 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/forum?id=bqiRIs3fJNk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://openreview.net/pdf?id=bqiRIs3fJNk" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2023/Online-non-episodic-RL/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/RL_diff_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>We consider the Reinforcement Learning problem of controlling an unknown dynamical system to maximise the long-term average reward along a single trajectory. Most of the literature considers system interactions that occur in discrete time and discrete state-action spaces. Although this standpoint is suitable for games, it is often inadequate for mechanical or digital systems in which interactions occur at a high frequency, if not in continuous time, and whose state spaces are large if not inherently continuous. Perhaps the only exception is the Linear Quadratic framework for which results exist both in discrete and continuous time. However, its ability to handle continuous states comes with the drawback of a rigid dynamic and reward structure. This work aims to overcome these shortcomings by modelling interaction times with a Poisson clock of frequency \varepsilon^-1, which captures arbitrary time scales: from discrete (\varepsilon=1) to continuous time (\varepsilon\downarrow0). In addition, we consider a generic reward function and model the state dynamics according to a jump process with an arbitrary transition kernel on \mathbbR^d. We show that the celebrated optimism protocol applies when the sub-tasks (learning and planning) can be performed effectively. We tackle learning within the eluder dimension framework and propose an approximate planning method based on a diffusive limit approximation of the jump process. Overall, our algorithm enjoys a regret of order \tilde\mathcalO(\varepsilon^1/2 T+\sqrtT). As the frequency of interactions blows up, the approximation error \varepsilon^1/2 T vanishes, showing that \tilde\mathcalO(\sqrtT) is attainable in near-continuous time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAB23EWRL</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Reinforcement Learning in near-continuous time for continuous state-action spaces}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Bouchard, Bruno}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Sixteenth European Workshop on Reinforcement Learning}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=bqiRIs3fJNk}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_4322.jpg"></div> <div id="ABC22" class="col-sm-8"> <div class="title">Diffusive limit approximation of pure jump optimal ergodic control problems</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a>,¬†and¬†<em>Lorenzo Croissant</em> </div> <div class="periodical"> 25‚Äì28 feb 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2209.15284" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2022/Diffusion-limit-ergodic-optimal-control/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/diffusion_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>Motivated by the design of fast reinforcement learning algorithms, we study the diffusive limit of a class of pure jump ergodic stochastic control problems. We show that, whenever the intensity of jumps is large enough, the approximation error is governed by the H√∂lder continuity of the Hessian matrix of the solution to the limit ergodic partial differential equation. This extends to this context the results of [1] obtained for finite horizon problems. We also explain how to construct a first order error correction term under appropriate smoothness assumptions. Finally, we quantify the error induced by the use of the Markov control policy constructed from the numerical finite difference scheme associated to the limit diffusive problem, this seems to be new in the literature and of its own interest. This approach permits to reduce very significantly the numerical resolution cost.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ABC22</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/ARXIV.2209.15284}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abeille, Marc and Bouchard, Bruno and Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Optimization and Control (math.OC), FOS: Mathematics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusive limit approximation of pure jump optimal ergodic control problems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">copyright</span> <span class="p">=</span> <span class="s">{arXiv.org perpetual, non-exclusive license}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5515.jpg"></div> <div id="ABC21" class="col-sm-8"> <div class="title">Diffusive limit approximation of pure-jump optimal stochastic control problems</div> <div class="author"> <a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†<a href="https://www.ceremade.dauphine.fr/~bouchard/bouchard.htm" target="_blank" rel="noopener noreferrer">Bruno Bouchard</a>,¬†and¬†<em>Lorenzo Croissant</em> </div> <div class="periodical"> <em>Journal of Optimization Theory and Applications</em> 25‚Äì28 feb 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2106.12848" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2106.12848" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2106.12848" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2021/Diffusion-limit-control/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/diffusion_limit/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>We consider the diffusive limit of a typical pure-jump Markovian control problem as the intensity of the driving Poisson process tends to infinity. We show that the convergence speed is provided by the H√∂lder constant of the Hessian of the limit problem, and explain how correction terms can be constructed. This provides an alternative efficient method for the numerical approximation of the optimal control of a pure-jump problem in situations with very high intensity of jump. We illustrate this approach in the context of a display advertising auction problem.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ABC21</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Diffusive limit approximation of pure-jump optimal stochastic control problems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Abeille, Marc and Bouchard, Bruno and Croissant, Lorenzo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Optimization Theory and Applications}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--30}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{ 10.1007/s10957-022-02135-7}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.1007/s10957-022-02135-7}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Optimization and Control (math.OC), FOS: Mathematics, FOS: Mathematics}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="year">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/IMG_5318.jpg"></div> <div id="CAC20" class="col-sm-8"> <div class="title">Real-Time Optimisation for Online Learning in Auctions</div> <div class="author"> <em>Lorenzo Croissant</em>,¬†<a href="https://scholar.google.fr/citations?user=0WsQ0uUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Marc Abeille</a>,¬†and¬†<a href="https://scholar.google.fr/citations?user=lFsKnyUAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">Clement Calauzenes</a> </div> <div class="periodical"> <em>In Proceedings of the 37th International Conference on Machine Learning</em> 13‚Äì18 jul 2020 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2010.10070" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://proceedings.mlr.press/v119/croissant20a.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://arxiv.org/pdf/2010.10070" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> <a href="/blog/2020/Online-learning-in-online-auctions/" class="btn btn-sm z-depth-0" role="button">Blog</a> <a href="/projects/Online_learning_auctions/" class="btn btn-sm z-depth-0" role="button">Project</a> </div> <div class="abstract hidden"> <p>In display advertising, a small group of sellers and bidders face each other in up to 10^12 auctions a day. In this context, revenue maximisation via monopoly price learning is a high-value problem for sellers. By nature, these auctions are online and produce a very high frequency stream of data. This results in a computational strain that requires algorithms be real-time. Unfortunately, existing methods inherited from the batch setting suffer O(\sqrtt) time/memory complexity at each update, prohibiting their use. In this paper, we provide the first algorithm for online learning of monopoly prices in online auctions whose update is constant in time and memory.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">CAC20</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Real-Time Optimisation for Online Learning in Auctions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Croissant, Lorenzo and Abeille, Marc and Calauzenes, Clement}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 37th International Conference on Machine Learning}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2217--2226}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{III, Hal Daum√© and Singh, Aarti}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{119}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Proceedings of Machine Learning Research}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="s">{13--18 Jul}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{PMLR}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Lorenzo Croissant. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos by myself. Last updated: October 17, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],tags:"ams",maxBuffer:10240,maxMacros:10240}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>